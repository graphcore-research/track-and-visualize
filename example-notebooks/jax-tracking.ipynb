{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Numerics in Jax / Flax\n",
    "Simple MNIST MLP example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (0.4.31)\n",
      "Requirement already satisfied: flax in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: optax in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (0.2.3)\n",
      "Requirement already satisfied: jaxlib<=0.4.31,>=0.4.30 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from jax) (0.4.31)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from jax) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.24 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from jax) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.10 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from jax) (1.14.1)\n",
      "Requirement already satisfied: msgpack in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from flax) (1.0.8)\n",
      "Requirement already satisfied: orbax-checkpoint in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from flax) (0.6.1)\n",
      "Requirement already satisfied: tensorstore in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from flax) (0.1.64)\n",
      "Requirement already satisfied: rich>=11.1 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from flax) (13.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from flax) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from flax) (6.0.2)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from optax) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.86 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from optax) (0.1.86)\n",
      "Requirement already satisfied: etils[epy] in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from optax) (1.9.2)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from chex>=0.1.86->optax) (0.12.1)\n",
      "Requirement already satisfied: setuptools in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from chex>=0.1.86->optax) (74.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from rich>=11.1->flax) (2.18.0)\n",
      "Requirement already satisfied: nest_asyncio in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: protobuf in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from orbax-checkpoint->flax) (5.28.0)\n",
      "Requirement already satisfied: humanize in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from orbax-checkpoint->flax) (4.10.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from etils[epy]->optax) (2024.6.1)\n",
      "Requirement already satisfied: importlib_resources in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from etils[epy]->optax) (6.4.4)\n",
      "Requirement already satisfied: zipp in /Users/colmb/numerics-vis/.venv/lib/python3.12/site-packages (from etils[epy]->optax) (3.20.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed\n",
    "!pip install jax flax optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 The JAX Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# Modified by Graphcore Ltd 2024.\n",
    "\n",
    "\n",
    "\"\"\"Datasets used in examples.\"\"\"\n",
    "\n",
    "\n",
    "import array\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import struct\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "_DATA = \"/tmp/jax_example_data/\"\n",
    "\n",
    "\n",
    "def _download(url, filename):\n",
    "    \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
    "    if not path.exists(_DATA):\n",
    "        os.makedirs(_DATA)\n",
    "    out_file = path.join(_DATA, filename)\n",
    "    if not path.isfile(out_file):\n",
    "        urllib.request.urlretrieve(url, out_file)\n",
    "        print(f\"downloaded {url} to {_DATA}\")\n",
    "\n",
    "\n",
    "def _partial_flatten(x):\n",
    "    \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
    "    return np.reshape(x, (x.shape[0], -1))\n",
    "\n",
    "\n",
    "def _one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "\n",
    "def _unzip(file):\n",
    "    file = tarfile.open(file)\n",
    "    file.extractall(_DATA)\n",
    "    file.close()\n",
    "    return\n",
    "\n",
    "\n",
    "def _unpickle(file):\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "\n",
    "def mnist_raw():\n",
    "    \"\"\"Download and parse the raw MNIST dataset.\"\"\"\n",
    "    # CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
    "    base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "\n",
    "    def parse_labels(filename):\n",
    "        with gzip.open(filename, \"rb\") as fh:\n",
    "            _ = struct.unpack(\">II\", fh.read(8))\n",
    "            return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
    "\n",
    "    def parse_images(filename):\n",
    "        with gzip.open(filename, \"rb\") as fh:\n",
    "            _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
    "            return np.array(array.array(\"B\", fh.read()), dtype=np.uint8).reshape(num_data, rows, cols)\n",
    "\n",
    "    for filename in [\n",
    "        \"train-images-idx3-ubyte.gz\",\n",
    "        \"train-labels-idx1-ubyte.gz\",\n",
    "        \"t10k-images-idx3-ubyte.gz\",\n",
    "        \"t10k-labels-idx1-ubyte.gz\",\n",
    "    ]:\n",
    "        _download(base_url + filename, filename)\n",
    "\n",
    "    train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
    "    train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
    "    test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
    "    test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def mnist(permute_train=False):\n",
    "    \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
    "    train_images, train_labels, test_images, test_labels = mnist_raw()\n",
    "\n",
    "    train_images = _partial_flatten(train_images) / np.float32(255.0)\n",
    "    test_images = _partial_flatten(test_images) / np.float32(255.0)\n",
    "    train_labels = _one_hot(train_labels, 10)\n",
    "    test_labels = _one_hot(test_labels, 10)\n",
    "\n",
    "    if permute_train:\n",
    "        perm = np.random.RandomState(0).permutation(train_images.shape[0])\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import linen as nn  # type:ignore\n",
    "from tandv.track.jax import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from jax.scipy.special import logsumexp\n",
    "\n",
    "\n",
    "def logsumexp(a, axis=None, keepdims=False):\n",
    "    from jax import lax\n",
    "\n",
    "    dims = (axis,)\n",
    "    amax = jnp.max(a, axis=dims, keepdims=keepdims)\n",
    "    # FIXME: not proper scale propagation, introducing NaNs\n",
    "    # amax = lax.stop_gradient(lax.select(jnp.isfinite(amax), amax, lax.full_like(amax, 0)))\n",
    "    amax = lax.stop_gradient(amax)\n",
    "    out = lax.sub(a, amax)\n",
    "    out = lax.exp(out)\n",
    "    out = lax.add(lax.log(jnp.sum(out, axis=dims, keepdims=keepdims)), amax)\n",
    "    return out\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"A simple 3 layers MLP model.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=512, use_bias=True)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=512, use_bias=True)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10, use_bias=True)(x)\n",
    "        logprobs = x - logsumexp(x, axis=1, keepdims=True)\n",
    "        return logprobs\n",
    "\n",
    "\n",
    "def loss(model, params, batch):\n",
    "    inputs, targets = batch\n",
    "    preds = model.apply(params, inputs)\n",
    "    # targets = jsa.lax.rebalance(targets, np.float32(1 / 8))\n",
    "    return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "\n",
    "\n",
    "def accuracy(model, params, batch):\n",
    "    inputs, targets = batch\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    preds = model.apply(params, inputs)\n",
    "    predicted_class = jnp.argmax(preds, axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "\n",
    "def update(model, optimizer, model_state, opt_state, batch):\n",
    "    grads = jax.grad(partial(loss, model))(model_state, batch)\n",
    "    # Optimizer update (state & gradients).\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, model_state)\n",
    "    model_state = optax.apply_updates(model_state, updates)\n",
    "    return model_state, opt_state, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output LogFrame is available at: /Users/colmb/numerics-vis/example-notebooks/tandv/damp-manuscript/final_logframe.pkl\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.001\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "key = jax.random.PRNGKey(42)\n",
    "use_scalify: bool = True\n",
    "\n",
    "training_dtype = np.dtype(np.float16)\n",
    "optimizer_dtype = np.dtype(np.float16)\n",
    "scale_dtype = np.float32\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = mnist()\n",
    "num_train = train_images.shape[0]\n",
    "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "num_batches = num_complete_batches + bool(leftover)\n",
    "mnist_img_size = train_images.shape[-1]\n",
    "\n",
    "def data_stream():\n",
    "    rng = np.random.RandomState(0)\n",
    "    while True:\n",
    "        perm = rng.permutation(num_train)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size : (i + 1) * batch_size]\n",
    "            yield train_images[batch_idx], train_labels[batch_idx]\n",
    "\n",
    "# Build model & initialize model parameters.\n",
    "model = MLP()\n",
    "model_state = model.init(key, np.zeros((batch_size, mnist_img_size), dtype=training_dtype))\n",
    "# Optimizer & optimizer state.\n",
    "opt = optax.adam(learning_rate=step_size, eps=2**-16)\n",
    "opt_state = opt.init(model_state)\n",
    "\n",
    "\n",
    "batches = data_stream()\n",
    "\n",
    "with track(model_state=model_state,optimizer_state=opt_state,track_gradients=True) as tracker: # wrap training loop in TorchTracker context manager\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            batch = next(batches)\n",
    "\n",
    "            model_state, opt_state, grads = tracker.intercept(update,model,opt,model_state, opt_state, batch) # pass update fn & args into intercept method (capture activations & grads)\n",
    "            tracker.step(model_state, opt_state, grads) # call step and pass pytrees for whatever you're tracking as args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">metadata</th>\n",
       "      <th colspan=\"5\" halign=\"left\">scalar_stats</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">exponent_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>tensor_type</th>\n",
       "      <th>dtype</th>\n",
       "      <th>max_abs</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>min_abs</th>\n",
       "      <th>rm2</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dense_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Weights</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>1.872651e-05</td>\n",
       "      <td>0.029328</td>\n",
       "      <td>4.747923e-07</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Dense_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Weights</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.100479</td>\n",
       "      <td>-6.272813e-05</td>\n",
       "      <td>0.036273</td>\n",
       "      <td>2.722679e-07</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Dense_2</td>\n",
       "      <td>None</td>\n",
       "      <td>Weights</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.100483</td>\n",
       "      <td>5.343384e-04</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>9.199790e-06</td>\n",
       "      <td>0.044167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Dense_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Optimiser_State                               ...</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Dense_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Optimiser_State                               ...</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28135</th>\n",
       "      <td>1406</td>\n",
       "      <td>Dense_1</td>\n",
       "      <td>&lt;class 'flax.linen.linear.Dense'&gt;</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>3.508286e-08</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28136</th>\n",
       "      <td>1406</td>\n",
       "      <td>Dense_0</td>\n",
       "      <td>&lt;class 'flax.linen.linear.Dense'&gt;</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.014246</td>\n",
       "      <td>2.012506e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28137</th>\n",
       "      <td>1406</td>\n",
       "      <td>Dense_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Weight_Gradients</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>1.756449e-05</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28138</th>\n",
       "      <td>1406</td>\n",
       "      <td>Dense_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Weight_Gradients</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>-8.185178e-08</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28139</th>\n",
       "      <td>1406</td>\n",
       "      <td>Dense_2</td>\n",
       "      <td>None</td>\n",
       "      <td>Weight_Gradients</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>-1.377771e-10</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28140 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      metadata                                              \\\n",
       "          step     name                               type   \n",
       "0            0  Dense_0                               None   \n",
       "1            0  Dense_1                               None   \n",
       "2            0  Dense_2                               None   \n",
       "3            0  Dense_0                               None   \n",
       "4            0  Dense_1                               None   \n",
       "...        ...      ...                                ...   \n",
       "28135     1406  Dense_1  <class 'flax.linen.linear.Dense'>   \n",
       "28136     1406  Dense_0  <class 'flax.linen.linear.Dense'>   \n",
       "28137     1406  Dense_0                               None   \n",
       "28138     1406  Dense_1                               None   \n",
       "28139     1406  Dense_2                               None   \n",
       "\n",
       "                                                                   \\\n",
       "                                             tensor_type    dtype   \n",
       "0                                                Weights  float32   \n",
       "1                                                Weights  float32   \n",
       "2                                                Weights  float32   \n",
       "3      Optimiser_State                               ...  float32   \n",
       "4      Optimiser_State                               ...  float32   \n",
       "...                                                  ...      ...   \n",
       "28135                                           Gradient  float32   \n",
       "28136                                           Gradient  float32   \n",
       "28137                                   Weight_Gradients  float32   \n",
       "28138                                   Weight_Gradients  float32   \n",
       "28139                                   Weight_Gradients  float32   \n",
       "\n",
       "      scalar_stats                                                  ...  \\\n",
       "           max_abs          mean  mean_abs       min_abs       rm2  ...   \n",
       "0         0.081203  1.872651e-05  0.029328  4.747923e-07  0.035703  ...   \n",
       "1         0.100479 -6.272813e-05  0.036273  2.722679e-07  0.044156  ...   \n",
       "2         0.100483  5.343384e-04  0.036234  9.199790e-06  0.044167  ...   \n",
       "3         0.000000  0.000000e+00  0.000000  0.000000e+00  0.000000  ...   \n",
       "4         0.000000  0.000000e+00  0.000000  0.000000e+00  0.000000  ...   \n",
       "...            ...           ...       ...           ...       ...  ...   \n",
       "28135     0.002142  3.508286e-08  0.000014  0.000000e+00  0.000096  ...   \n",
       "28136     0.014246  2.012506e-06  0.000022  0.000000e+00  0.000248  ...   \n",
       "28137     0.015556  1.756449e-05  0.000177  0.000000e+00  0.000666  ...   \n",
       "28138     0.003809 -8.185178e-08  0.000137  0.000000e+00  0.000288  ...   \n",
       "28139     0.018990 -1.377771e-10  0.001873  0.000000e+00  0.003539  ...   \n",
       "\n",
       "      exponent_counts                              \n",
       "                    8  9 10 11 12 13 14 15 16 inf  \n",
       "0                   0  0  0  0  0  0  0  0  0   0  \n",
       "1                   0  0  0  0  0  0  0  0  0   0  \n",
       "2                   0  0  0  0  0  0  0  0  0   0  \n",
       "3                   0  0  0  0  0  0  0  0  0   0  \n",
       "4                   0  0  0  0  0  0  0  0  0   0  \n",
       "...               ... .. .. .. .. .. .. .. ..  ..  \n",
       "28135               0  0  0  0  0  0  0  0  0   0  \n",
       "28136               0  0  0  0  0  0  0  0  0   0  \n",
       "28137               0  0  0  0  0  0  0  0  0   0  \n",
       "28138               0  0  0  0  0  0  0  0  0   0  \n",
       "28139               0  0  0  0  0  0  0  0  0   0  \n",
       "\n",
       "[28140 rows x 48 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tandv.track.common import read_pickle\n",
    "read_pickle('/Users/colmb/numerics-vis/example-notebooks/tandv/damp-manuscript/final_logframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
