{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# add local lib to sys path for relative import\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.log.common._types import LogFrame\n",
    "# Load DF\n",
    "df = pd.read_pickle('../test-data/numerics_df_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaException(Exception):\n",
    "    \"\"\"The provided DataFrame does not have a valid schema. See schema_migration and/or \n",
    "    LogFrame.schema to rectify the issue\"\"\"\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.util import hash_pandas_object\n",
    "import hashlib\n",
    "\n",
    "def _get_df_hash(df: pd.DataFrame):\n",
    "    \"\"\"Gets A SHA-256 Hash of the dataframe - does not conside attr values\"\"\"\n",
    "    return int(hashlib.sha256(pd.util.hash_pandas_object(df, index=True).values).hexdigest(), 16)\n",
    "\n",
    "def validate_schema(df: pd.DataFrame, SCHEMA = LogFrame):\n",
    "    from pandas.api.types import is_string_dtype, is_integer_dtype, is_float_dtype, is_dtype_equal\n",
    "    import typing\n",
    "    # get lf schema as Dict[tuple(tl_col, col) : type]\n",
    "    comp_fn = {\n",
    "        str: is_string_dtype,\n",
    "        int: is_integer_dtype,\n",
    "        float: is_float_dtype\n",
    "    }\n",
    "    schema, wcs = SCHEMA.get_flat_schema()\n",
    "\n",
    "    def _check_dtype(col, key_map = None) -> bool:\n",
    "        # uses outer fn varaibles, schema, comp_fn and df\n",
    "        dtype_opt = schema[col] if key_map == None else wcs[key_map].dtype\n",
    "\n",
    "        if typing.get_origin(dtype_opt) == typing.Union:\n",
    "            # iterate over args\n",
    "            for arg in typing.get_args(dtype_opt):\n",
    "                if arg != None:\n",
    "                    # check it is this type\n",
    "                    if comp_fn[arg](df.dtypes[col]):\n",
    "                        # if so return True\n",
    "                        return True\n",
    "        # must be a single type                \n",
    "        else:\n",
    "            # check if Dtype matches\n",
    "            if (comp_fn[dtype_opt](df.dtypes[col])):\n",
    "                # if so return true\n",
    "                return True\n",
    "        # No Dtype matches .. return false\n",
    "        return False\n",
    "    \n",
    "    def _check_wildcard(col):\n",
    "        # checks if the column tuple matches a wildcard, if the count is correct,\n",
    "        # create temporary key mappings -> this assumes that there's only 1 wild card per higherlevel index (which may not be valid)\n",
    "        # also very inefficient as is done per wildcard check!\n",
    "        t_col = (col[0], '*')\n",
    "        tmp_wcs, map_wcs = {},{}\n",
    "        for k,v in wcs.items():\n",
    "            new_key = (k[0], str(k[1]()))\n",
    "            tmp_wcs[new_key] = v\n",
    "            map_wcs[new_key] = k\n",
    "\n",
    "        if t_col in tmp_wcs.keys():\n",
    "            map_key = map_wcs[t_col]\n",
    "\n",
    "            if _check_dtype(col, map_key):\n",
    "                # dtype matches -> make sure it doesn't break WC Constraints\n",
    "                wcs[map_key].count += 1\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    counter = 0 \n",
    "    # iterate over columns\n",
    "    for col in df.columns:\n",
    "        schema_match = False\n",
    "        # easy match\n",
    "        if col in schema.keys():\n",
    "            # check if union\n",
    "            schema_match = _check_dtype(col=col)\n",
    "            \n",
    "\n",
    "        # Wildcard Match\n",
    "        elif _check_wildcard:\n",
    "            counter += 1\n",
    "        else:\n",
    "            ...\n",
    "        # if the column matches the schema, then increment counter\n",
    "        if schema_match:\n",
    "            counter += 1\n",
    "\n",
    "    \n",
    "    # if all columns don't pass validation, Raise Schema Exception\n",
    "    if counter != len(df.columns):\n",
    "        raise SchemaException\n",
    "\n",
    "    # Make sure WildCards match  \n",
    "    for key, value in wcs.items():\n",
    "        if value.count >= key[1].max or value.count < key[1].min:\n",
    "            raise SchemaException\n",
    "\n",
    "    df.attrs['vis-meta'] = {\n",
    "        'hash': _get_df_hash(df)}\n",
    "    return df\n",
    "\n",
    "\n",
    "df2 = validate_schema(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
